{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2998ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Advanced Lagrange Multiplier Solver for Scientific Computing\n",
    "===========================================================\n",
    "\n",
    "A comprehensive Python implementation for solving constrained optimization problems\n",
    "using the method of Lagrange multipliers with advanced numerical techniques,\n",
    "visualization, and analysis capabilities.\n",
    "\n",
    "Features:\n",
    "- Multiple constraint handling\n",
    "- Numerical and symbolic solutions\n",
    "- Interactive visualization\n",
    "- Solution verification and analysis\n",
    "- Export capabilities\n",
    "- Comprehensive error handling\n",
    "\n",
    "This script provides a robust framework for solving optimization problems of the form:\n",
    "\n",
    "  Minimize/Maximize f(x₁, x₂, ..., xₙ)\n",
    "  Subject to: g₁(x₁, x₂, ..., xₙ) = 0, g₂(x₁, x₂, ..., xₙ) = 0, ...\n",
    "\n",
    "The core of the solver is the `AdvancedLagrangeOptimizer` class, which handles the entire\n",
    "optimization pipeline from problem definition to result analysis and visualization.\n",
    "It leverages powerful libraries like SymPy for symbolic manipulation and SciPy for\n",
    "numerical optimization, combining the strengths of both approaches.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ==============================================================================\n",
    "# IMPORTS AND CONFIGURATION\n",
    "# ==============================================================================\n",
    "# This section imports all necessary libraries and configures the environment.\n",
    "# `numpy` is used for numerical operations, `sympy` for symbolic math,\n",
    "# `matplotlib.pyplot` and `seaborn` for plotting and visualization, and `pandas`\n",
    "# for data analysis and tabular output.\n",
    "# `scipy.optimize` provides the numerical solvers, while other standard libraries\n",
    "# handle tasks like logging, file I/O, and data typing.\n",
    "\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize, fsolve\n",
    "import warnings\n",
    "import json\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Union, Tuple, Optional\n",
    "import logging\n",
    "\n",
    "# Configure logging to provide informative messages about the solver's progress.\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set plotting style for aesthetic visualizations.\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "# Suppress specific runtime warnings from numerical libraries for cleaner output.\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "# ==============================================================================\n",
    "# MAIN CLASS: AdvancedLagrangeOptimizer\n",
    "# ==============================================================================\n",
    "# This class encapsulates all the functionality for the Lagrange multiplier solver.\n",
    "# It is designed to be highly modular and extensible.\n",
    "\n",
    "class AdvancedLagrangeOptimizer:\n",
    "    \"\"\"\n",
    "    Advanced Lagrange multiplier solver with comprehensive features for scientific computing.\n",
    "    \n",
    "    The class manages the entire process: problem setup, Lagrangian formulation,\n",
    "    solving using both symbolic and numerical methods, solution validation,\n",
    "    visualization, and result analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, verbose: bool = True):\n",
    "        \"\"\"\n",
    "        Initializes the optimizer.\n",
    "        \n",
    "        Args:\n",
    "            verbose (bool): If True, enables detailed print statements and logging\n",
    "                            to show the steps of the solving process.\n",
    "        \"\"\"\n",
    "        self.verbose = verbose\n",
    "        self.solutions = []\n",
    "        self.lagrangian = None\n",
    "        self.variables = None\n",
    "        self.multipliers = None\n",
    "        self.objective = None\n",
    "        self.constraints = []\n",
    "        self.problem_type = 'minimize'\n",
    "        \n",
    "    def setup_problem(self, \n",
    "                      objective: Union[str, sp.Expr],\n",
    "                      constraints: Union[List[str], List[sp.Expr]],\n",
    "                      variables: Union[List[str], List[sp.Symbol]],\n",
    "                      problem_type: str = 'minimize') -> None:\n",
    "        \"\"\"\n",
    "        Sets up the optimization problem.\n",
    "        \n",
    "        This method parses the user-provided objective function, constraints, and\n",
    "        variables, converting them into SymPy objects. It then constructs the\n",
    "        Lagrangian function, which is the cornerstone of the Lagrange multiplier method.\n",
    "        \n",
    "        The Lagrangian is defined as L(x, λ) = f(x) - Σ(λᵢ * gᵢ(x)), where f is the\n",
    "        objective function and gᵢ are the constraint functions.\n",
    "        \n",
    "        Args:\n",
    "            objective: The function to be optimized, as a string or SymPy expression.\n",
    "            constraints: A list of constraint equations, which are assumed to be equal to zero.\n",
    "                         e.g., for `x + y = 1`, the constraint is `x + y - 1`.\n",
    "            variables: A list of the problem's variables.\n",
    "            problem_type: 'minimize' or 'maximize'. The solver adjusts the objective\n",
    "                          function for maximization problems by minimizing its negative.\n",
    "        \"\"\"\n",
    "        self.problem_type = problem_type.lower()\n",
    "        \n",
    "        # Convert string inputs to SymPy objects for symbolic manipulation.\n",
    "        if isinstance(variables[0], str):\n",
    "            self.variables = [sp.Symbol(var) for var in variables]\n",
    "        else:\n",
    "            self.variables = variables\n",
    "            \n",
    "        if isinstance(objective, str):\n",
    "            self.objective = sp.sympify(objective)\n",
    "        else:\n",
    "            self.objective = objective\n",
    "            \n",
    "        self.constraints = []\n",
    "        for constraint in constraints:\n",
    "            if isinstance(constraint, str):\n",
    "                self.constraints.append(sp.sympify(constraint))\n",
    "            else:\n",
    "                self.constraints.append(constraint)\n",
    "        \n",
    "        # Create symbolic Lagrange multipliers, one for each constraint.\n",
    "        self.multipliers = [sp.Symbol(f'λ{i+1}') for i in range(len(self.constraints))]\n",
    "        \n",
    "        # Construct the Lagrangian function.\n",
    "        self._construct_lagrangian()\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"Problem setup complete:\")\n",
    "            print(f\"Type: {self.problem_type.capitalize()}\")\n",
    "            print(f\"Variables: {[str(v) for v in self.variables]}\")\n",
    "            print(f\"Objective: {self.objective}\")\n",
    "            print(f\"Constraints: {[str(c) for c in self.constraints]}\")\n",
    "    \n",
    "    def _construct_lagrangian(self) -> None:\n",
    "        \"\"\"\n",
    "        Constructs the Lagrangian function.\n",
    "        \n",
    "        This is a private helper method that computes the Lagrangian L = f - Σ(λᵢ*gᵢ)\n",
    "        based on the problem's objective function and constraints.\n",
    "        \"\"\"\n",
    "        lagrangian = self.objective.copy()\n",
    "        \n",
    "        for i, constraint in enumerate(self.constraints):\n",
    "            lagrangian -= self.multipliers[i] * constraint\n",
    "            \n",
    "        self.lagrangian = lagrangian\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\\nLagrangian: {self.lagrangian}\")\n",
    "    \n",
    "    def solve_symbolic(self) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Solves the optimization problem symbolically using SymPy.\n",
    "        \n",
    "        This method finds the critical points of the Lagrangian by solving the system\n",
    "        of equations formed by setting the partial derivatives of the Lagrangian\n",
    "        with respect to all variables and multipliers to zero (∇L = 0). This is\n",
    "        the fundamental principle of the Lagrange multiplier method.\n",
    "        \n",
    "        The equations solved are:\n",
    "          ∂L/∂xᵢ = 0  (for each variable xᵢ)\n",
    "          ∂L/∂λⱼ = 0  (for each multiplier λⱼ, which simplifies to the original constraint gⱼ=0)\n",
    "          \n",
    "        Returns:\n",
    "            A list of dictionaries, where each dictionary represents a solution\n",
    "            and contains the values of variables, multipliers, and the objective function.\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"SYMBOLIC SOLUTION\")\n",
    "            print(\"=\"*60)\n",
    "        \n",
    "        try:\n",
    "            # Compute partial derivatives of the Lagrangian.\n",
    "            gradient_eqs = []\n",
    "            \n",
    "            # The gradient with respect to variables.\n",
    "            for var in self.variables:\n",
    "                grad_eq = sp.diff(self.lagrangian, var)\n",
    "                gradient_eqs.append(grad_eq)\n",
    "                if self.verbose:\n",
    "                    print(f\"∂L/∂{var} = {grad_eq} = 0\")\n",
    "            \n",
    "            # The gradient with respect to multipliers gives back the constraints.\n",
    "            gradient_eqs.extend(self.constraints)\n",
    "            if self.verbose:\n",
    "                print(f\"Constraints: {[str(c) for c in self.constraints]}\")\n",
    "            \n",
    "            # Use SymPy's `solve` function to find all possible solutions.\n",
    "            all_vars = self.variables + self.multipliers\n",
    "            solutions = sp.solve(gradient_eqs, all_vars, dict=True)\n",
    "            \n",
    "            if not solutions:\n",
    "                if self.verbose:\n",
    "                    print(\"No symbolic solutions found. Trying numerical methods...\")\n",
    "                return []\n",
    "            \n",
    "            # Process and filter the solutions, e.g., to discard complex solutions.\n",
    "            processed_solutions = []\n",
    "            for sol in solutions:\n",
    "                processed_sol = self._process_solution(sol)\n",
    "                if processed_sol:\n",
    "                    processed_solutions.append(processed_sol)\n",
    "            \n",
    "            self.solutions = processed_solutions\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"\\nFound {len(processed_solutions)} symbolic solution(s)\")\n",
    "                for i, sol in enumerate(processed_solutions):\n",
    "                    print(f\"\\nSolution {i+1}:\")\n",
    "                    for key, value in sol.items():\n",
    "                        if key != 'objective_value' and key != 'constraint_values':\n",
    "                            print(f\"  {key} = {value}\")\n",
    "                    print(f\"  Objective value = {sol['objective_value']}\")\n",
    "            \n",
    "            return processed_solutions\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Symbolic solution failed: {e}\")\n",
    "            if self.verbose:\n",
    "                print(f\"Symbolic solution failed: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def solve_numerical(self, \n",
    "                        num_random_starts: int = 50,\n",
    "                        bounds: Optional[List[Tuple]] = None,\n",
    "                        method: str = 'SLSQP') -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Solves the optimization problem using numerical methods.\n",
    "        \n",
    "        This method uses `scipy.optimize.minimize`, a powerful numerical solver for\n",
    "        constrained optimization. Since numerical methods are sensitive to the\n",
    "        starting point, this function uses multiple random starts to increase the\n",
    "        likelihood of finding the global optimum.\n",
    "        \n",
    "        Args:\n",
    "            num_random_starts: The number of random initial guesses to use for the solver.\n",
    "                               This helps in escaping local minima.\n",
    "            bounds: A list of tuples `(min, max)` for each variable, defining the\n",
    "                    search space. If None, defaults to `(-10, 10)` for each variable.\n",
    "            method: The specific optimization algorithm to use from SciPy. 'SLSQP'\n",
    "                    (Sequential Least Squares Programming) is a good default for\n",
    "                    equality-constrained problems.\n",
    "        \n",
    "        Returns:\n",
    "            A list of unique, valid numerical solutions found.\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"NUMERICAL SOLUTION\")\n",
    "            print(\"=\"*60)\n",
    "        \n",
    "        # Convert SymPy expressions into fast, callable numerical functions.\n",
    "        objective_func = sp.lambdify(self.variables, self.objective, 'numpy')\n",
    "        constraint_funcs = [sp.lambdify(self.variables, c, 'numpy') for c in self.constraints]\n",
    "        \n",
    "        # Set default bounds if not provided.\n",
    "        if bounds is None:\n",
    "            bounds = [(-10, 10)] * len(self.variables)\n",
    "        \n",
    "        solutions = []\n",
    "        \n",
    "        # Use a fixed random seed for reproducibility of results.\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        for i in range(num_random_starts):\n",
    "            # Generate a random starting point within the specified bounds.\n",
    "            x0 = np.array([np.random.uniform(b[0], b[1]) for b in bounds])\n",
    "            \n",
    "            try:\n",
    "                # Format constraints for SciPy's `minimize` function.\n",
    "                constraints = []\n",
    "                for j, cf in enumerate(constraint_funcs):\n",
    "                    constraints.append({\n",
    "                        'type': 'eq',\n",
    "                        'fun': lambda x, func=cf: func(*x)\n",
    "                    })\n",
    "                    \n",
    "                # The minimization algorithm minimizes, so negate the objective for maximization.\n",
    "                if self.problem_type == 'maximize':\n",
    "                    obj_func = lambda x: -objective_func(*x)\n",
    "                else:\n",
    "                    obj_func = lambda x: objective_func(*x)\n",
    "                    \n",
    "                # Run the numerical optimization.\n",
    "                result = minimize(obj_func, x0, method=method, \n",
    "                                  constraints=constraints, bounds=bounds,\n",
    "                                  options={'ftol': 1e-9, 'disp': False})\n",
    "                \n",
    "                if result.success:\n",
    "                    # Check if the found solution is close to satisfying the constraints.\n",
    "                    constraint_violations = [abs(cf(*result.x)) for cf in constraint_funcs]\n",
    "                    if all(cv < 1e-6 for cv in constraint_violations):\n",
    "                        \n",
    "                        # Store the valid solution.\n",
    "                        sol_dict = {}\n",
    "                        for j, var in enumerate(self.variables):\n",
    "                            sol_dict[str(var)] = float(result.x[j])\n",
    "                        \n",
    "                        # Calculate objective value (and restore the sign if maximizing).\n",
    "                        obj_val = float(objective_func(*result.x))\n",
    "                        sol_dict['objective_value'] = obj_val\n",
    "                        \n",
    "                        # The Lagrange multipliers are often returned by the solver, but if not,\n",
    "                        # they are estimated using the gradient information.\n",
    "                        if hasattr(result, 'multipliers') and result.multipliers is not None:\n",
    "                            for j, mult in enumerate(self.multipliers):\n",
    "                                if j < len(result.multipliers):\n",
    "                                    sol_dict[str(mult)] = float(result.multipliers[j])\n",
    "                        else:\n",
    "                            multipliers = self._estimate_multipliers(result.x)\n",
    "                            for j, mult in enumerate(self.multipliers):\n",
    "                                if j < len(multipliers):\n",
    "                                    sol_dict[str(mult)] = float(multipliers[j])\n",
    "                        \n",
    "                        sol_dict['constraint_values'] = constraint_violations\n",
    "                        solutions.append(sol_dict)\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.debug(f\"Numerical optimization attempt {i+1} failed: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Remove duplicate solutions that might have been found by different starts.\n",
    "        unique_solutions = self._remove_duplicate_solutions(solutions)\n",
    "        \n",
    "        # Sort solutions by objective value to easily find the best one.\n",
    "        unique_solutions.sort(key=lambda x: x['objective_value'])\n",
    "        \n",
    "        self.solutions.extend(unique_solutions)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\\nFound {len(unique_solutions)} numerical solution(s)\")\n",
    "            for i, sol in enumerate(unique_solutions[:5]):  # Show first 5\n",
    "                print(f\"\\nSolution {i+1}:\")\n",
    "                for key, value in sol.items():\n",
    "                    if key not in ['constraint_values']:\n",
    "                        if isinstance(value, float):\n",
    "                            print(f\"  {key} = {value:.6f}\")\n",
    "                        else:\n",
    "                            print(f\"  {key} = {value}\")\n",
    "    \n",
    "        return unique_solutions\n",
    "    \n",
    "    def _estimate_multipliers(self, x: np.ndarray) -> List[float]:\n",
    "        \"\"\"\n",
    "        Estimates the Lagrange multipliers using gradient information.\n",
    "        \n",
    "        This private method is used when the numerical solver does not return the\n",
    "        multipliers directly. It solves a linear system based on the gradient\n",
    "        condition of the Lagrange function: ∇f(x*) + Σ(λᵢ*∇gᵢ(x*)) = 0, where x* is\n",
    "        the optimal solution found.\n",
    "        \n",
    "        This system can be rearranged as A*λ = -∇f, where A is a matrix of the\n",
    "        constraint gradients. This is a robust way to estimate the multipliers.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Compute gradients of the objective and constraints numerically.\n",
    "            obj_grad = self._numerical_gradient(self.objective, x)\n",
    "            constraint_grads = [self._numerical_gradient(c, x) for c in self.constraints]\n",
    "            \n",
    "            # Form the matrix A and vector b for the linear system A*λ = -∇f.\n",
    "            A = np.column_stack(constraint_grads)\n",
    "            b = -obj_grad\n",
    "            \n",
    "            # Use `numpy.linalg.lstsq` to solve the least squares problem, which is\n",
    "            # robust even for over-determined or ill-conditioned systems.\n",
    "            multipliers, residuals, rank, s = np.linalg.lstsq(A.T, b, rcond=None)\n",
    "            \n",
    "            return multipliers.tolist()\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Multiplier estimation failed: {e}\")\n",
    "            return [0.0] * len(self.constraints)\n",
    "    \n",
    "    def _numerical_gradient(self, expr: sp.Expr, x: np.ndarray, h: float = 1e-8) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Computes the numerical gradient of an expression at a given point `x`.\n",
    "        \n",
    "        This method uses the central difference formula to approximate the partial\n",
    "        derivatives of a function. It's a key part of the multiplier estimation\n",
    "        process.\n",
    "        \n",
    "        Gradient at x ≈ [ (f(x+h*e₁) - f(x-h*e₁))/(2h), ..., (f(x+h*eₙ) - f(x-h*eₙ))/(2h) ]\n",
    "        where eᵢ is the i-th standard basis vector.\n",
    "        \"\"\"\n",
    "        func = sp.lambdify(self.variables, expr, 'numpy')\n",
    "        grad = np.zeros_like(x)\n",
    "        \n",
    "        for i in range(len(x)):\n",
    "            x_plus = x.copy()\n",
    "            x_minus = x.copy()\n",
    "            x_plus[i] += h\n",
    "            x_minus[i] -= h\n",
    "            \n",
    "            grad[i] = (func(*x_plus) - func(*x_minus)) / (2 * h)\n",
    "        \n",
    "        return grad\n",
    "    \n",
    "    def _process_solution(self, sol: Dict) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Processes and validates a symbolic solution.\n",
    "        \n",
    "        This helper method cleans up the solutions returned by SymPy, converting\n",
    "        them to floating-point numbers and discarding any complex solutions that\n",
    "        are not physically meaningful. It also calculates the objective value and\n",
    "        verifies that the constraints are satisfied.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            processed = {}\n",
    "            \n",
    "            # Extract variable values and check for imaginary parts.\n",
    "            for var in self.variables:\n",
    "                if var in sol:\n",
    "                    value = complex(sol[var])\n",
    "                    if abs(value.imag) < 1e-10:  # Check if the imaginary part is negligible.\n",
    "                        processed[str(var)] = float(value.real)\n",
    "                    else:\n",
    "                        return None  # Discard complex solutions.\n",
    "                else:\n",
    "                    return None\n",
    "            \n",
    "            # Extract multiplier values, handling cases where they might be zero or not present.\n",
    "            for mult in self.multipliers:\n",
    "                if mult in sol:\n",
    "                    value = complex(sol[mult])\n",
    "                    if abs(value.imag) < 1e-10:\n",
    "                        processed[str(mult)] = float(value.real)\n",
    "                    else:\n",
    "                        processed[str(mult)] = 0.0\n",
    "                else:\n",
    "                    processed[str(mult)] = 0.0\n",
    "            \n",
    "            # Calculate the objective value at the found solution.\n",
    "            var_values = [processed[str(var)] for var in self.variables]\n",
    "            obj_func = sp.lambdify(self.variables, self.objective, 'numpy')\n",
    "            processed['objective_value'] = float(obj_func(*var_values))\n",
    "            \n",
    "            # Verify that the constraint equations evaluate to zero (within tolerance).\n",
    "            constraint_values = []\n",
    "            for constraint in self.constraints:\n",
    "                const_func = sp.lambdify(self.variables, constraint, 'numpy')\n",
    "                constraint_values.append(float(const_func(*var_values)))\n",
    "            \n",
    "            processed['constraint_values'] = constraint_values\n",
    "            \n",
    "            return processed\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Solution processing failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _remove_duplicate_solutions(self, solutions: List[Dict], tolerance: float = 1e-6) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Removes duplicate solutions from a list.\n",
    "        \n",
    "        Numerical methods with multiple starts can converge to the same solution.\n",
    "        This function filters out duplicates by comparing the variable values\n",
    "        within a given tolerance.\n",
    "        \"\"\"\n",
    "        unique_solutions = []\n",
    "        \n",
    "        for sol in solutions:\n",
    "            is_duplicate = False\n",
    "            for unique_sol in unique_solutions:\n",
    "                # Compare variable values to check for duplicates.\n",
    "                differences = []\n",
    "                for var in self.variables:\n",
    "                    var_str = str(var)\n",
    "                    if var_str in sol and var_str in unique_sol:\n",
    "                        differences.append(abs(sol[var_str] - unique_sol[var_str]))\n",
    "                \n",
    "                if differences and max(differences) < tolerance:\n",
    "                    is_duplicate = True\n",
    "                    break\n",
    "            \n",
    "            if not is_duplicate:\n",
    "                unique_solutions.append(sol)\n",
    "        \n",
    "        return unique_solutions\n",
    "    \n",
    "    def verify_solutions(self) -> None:\n",
    "        \"\"\"\n",
    "        Verifies that the found solutions satisfy the Karush-Kuhn-Tucker (KKT) conditions.\n",
    "        \n",
    "        The KKT conditions are a generalization of the Lagrange multiplier method\n",
    "        for both equality and inequality constraints. For this solver, which only\n",
    "        handles equality constraints, the KKT conditions simplify to:\n",
    "          1. The solution must be on the constraint surface (g(x) = 0).\n",
    "          2. The gradient of the Lagrangian must be zero at the solution (∇L = 0).\n",
    "        \n",
    "        This method checks these conditions for each found solution and reports the status.\n",
    "        \"\"\"\n",
    "        if not self.solutions:\n",
    "            print(\"No solutions to verify.\")\n",
    "            return\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"SOLUTION VERIFICATION\")\n",
    "            print(\"=\"*60)\n",
    "        \n",
    "        for i, sol in enumerate(self.solutions):\n",
    "            if self.verbose:\n",
    "                print(f\"\\nVerifying Solution {i+1}:\")\n",
    "            \n",
    "            # Check constraint satisfaction.\n",
    "            constraint_satisfied = True\n",
    "            for j, constraint_val in enumerate(sol.get('constraint_values', [])):\n",
    "                satisfied = abs(constraint_val) < 1e-6\n",
    "                constraint_satisfied = constraint_satisfied and satisfied\n",
    "                if self.verbose:\n",
    "                    status = \"✓\" if satisfied else \"✗\"\n",
    "                    print(f\"  Constraint {j+1}: {constraint_val:.2e} {status}\")\n",
    "            \n",
    "            # Check the gradient condition (∇L = 0).\n",
    "            var_values = [sol[str(var)] for var in self.variables]\n",
    "            mult_values = [sol.get(str(mult), 0) for mult in self.multipliers]\n",
    "            \n",
    "            gradient_satisfied = True\n",
    "            for var in self.variables:\n",
    "                grad_val = sp.diff(self.lagrangian, var)\n",
    "                grad_func = sp.lambdify(self.variables + self.multipliers, grad_val, 'numpy')\n",
    "                grad_at_sol = grad_func(*(var_values + mult_values))\n",
    "                \n",
    "                satisfied = abs(grad_at_sol) < 1e-6\n",
    "                gradient_satisfied = gradient_satisfied and satisfied\n",
    "                if self.verbose:\n",
    "                    status = \"✓\" if satisfied else \"✗\"\n",
    "                    print(f\"  ∂L/∂{var} = {grad_at_sol:.2e} {status}\")\n",
    "            \n",
    "            overall_status = \"VALID\" if (constraint_satisfied and gradient_satisfied) else \"INVALID\"\n",
    "            if self.verbose:\n",
    "                print(f\"  Overall: {overall_status}\")\n",
    "    \n",
    "    def visualize_2d(self, \n",
    "                     x_range: Tuple[float, float] = (-5, 5),\n",
    "                     y_range: Tuple[float, float] = (-5, 5),\n",
    "                     resolution: int = 400) -> None:\n",
    "        \"\"\"\n",
    "        Creates an interactive 2D visualization for problems with two variables.\n",
    "        \n",
    "        This method generates two plots: a 2D contour plot and a 3D surface plot.\n",
    "        The contour plot shows the level sets of the objective function, with the\n",
    "        constraint curve(s) overlaid. The intersection of the constraint curve and\n",
    "        the contour lines indicates the solution. The 3D plot provides a spatial\n",
    "        representation of the objective function surface and the constraint curve.\n",
    "        \n",
    "        Args:\n",
    "            x_range: The plotting range for the x-axis.\n",
    "            y_range: The plotting range for the y-axis.\n",
    "            resolution: The number of points used to create the plotting grid.\n",
    "        \"\"\"\n",
    "        if len(self.variables) != 2:\n",
    "            print(\"2D visualization only available for 2-variable problems.\")\n",
    "            return\n",
    "        \n",
    "        x_var, y_var = self.variables\n",
    "        \n",
    "        # Create a meshgrid for plotting the functions over a 2D space.\n",
    "        x = np.linspace(x_range[0], x_range[1], resolution)\n",
    "        y = np.linspace(y_range[0], y_range[1], resolution)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        \n",
    "        # Evaluate the objective function on the grid.\n",
    "        obj_func = sp.lambdify([x_var, y_var], self.objective, 'numpy')\n",
    "        Z = obj_func(X, Y)\n",
    "        \n",
    "        # Create a figure with two subplots.\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # --- Contour Plot (ax1) ---\n",
    "        ax1 = axes[0]\n",
    "        contour = ax1.contour(X, Y, Z, levels=20, alpha=0.6)\n",
    "        ax1.clabel(contour, inline=True, fontsize=8)\n",
    "        contour_fill = ax1.contourf(X, Y, Z, levels=50, alpha=0.3, cmap='viridis')\n",
    "        plt.colorbar(contour_fill, ax=ax1, label='Objective Function')\n",
    "        \n",
    "        # Plot each constraint as a contour line where the function is zero.\n",
    "        for i, constraint in enumerate(self.constraints):\n",
    "            const_func = sp.lambdify([x_var, y_var], constraint, 'numpy')\n",
    "            C = const_func(X, Y)\n",
    "            ax1.contour(X, Y, C, levels=[0], colors=f'C{i+1}', linewidths=3, \n",
    "                        linestyles='--', alpha=0.8)\n",
    "        \n",
    "        # Plot the found solutions as prominent markers.\n",
    "        if self.solutions:\n",
    "            sol_x = [sol[str(x_var)] for sol in self.solutions if str(x_var) in sol]\n",
    "            sol_y = [sol[str(y_var)] for sol in self.solutions if str(y_var) in sol]\n",
    "            ax1.scatter(sol_x, sol_y, color='red', s=100, marker='*', \n",
    "                        edgecolors='black', linewidth=2, label='Solutions', zorder=5)\n",
    "        \n",
    "        ax1.set_xlabel(f'{x_var}')\n",
    "        ax1.set_ylabel(f'{y_var}')\n",
    "        ax1.set_title('Contour Plot with Constraints')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.legend()\n",
    "        \n",
    "        # --- 3D Surface Plot (ax2) ---\n",
    "        ax2 = fig.add_subplot(122, projection='3d')\n",
    "        surface = ax2.plot_surface(X, Y, Z, cmap='viridis', alpha=0.7)\n",
    "        \n",
    "        # Plot the constraint curves on the 3D surface, showing where the solutions lie.\n",
    "        for i, constraint in enumerate(self.constraints):\n",
    "            const_func = sp.lambdify([x_var, y_var], constraint, 'numpy')\n",
    "            C = const_func(X, Y)\n",
    "            ax2.contour(X, Y, C, levels=[0], colors=f'C{i+1}', linewidths=3,\n",
    "                        offset=np.min(Z), zdir='z', alpha=0.8)\n",
    "        \n",
    "        # Plot the solution points on the 3D surface.\n",
    "        if self.solutions:\n",
    "            sol_x = [sol[str(x_var)] for sol in self.solutions if str(x_var) in sol]\n",
    "            sol_y = [sol[str(y_var)] for sol in self.solutions if str(y_var) in sol]\n",
    "            sol_z = [sol['objective_value'] for sol in self.solutions]\n",
    "            ax2.scatter(sol_x, sol_y, sol_z, color='red', s=100, marker='*',\n",
    "                        edgecolors='black', linewidth=2, label='Solutions')\n",
    "        \n",
    "        ax2.set_xlabel(f'{x_var}')\n",
    "        ax2.set_ylabel(f'{y_var}')\n",
    "        ax2.set_zlabel('Objective Function')\n",
    "        ax2.set_title('3D Surface Plot')\n",
    "        \n",
    "        plt.colorbar(surface, ax=ax2, shrink=0.5, aspect=5, label='Objective Function')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def analyze_solutions(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Creates a detailed analysis of the found solutions.\n",
    "        \n",
    "        This method organizes the solution data (variable values, multipliers,\n",
    "        objective values, and constraint violations) into a pandas DataFrame,\n",
    "        which provides a clear, tabular summary. It also prints summary statistics\n",
    "        like the best, worst, and mean objective values.\n",
    "        \n",
    "        Returns:\n",
    "            A pandas DataFrame containing all solution data.\n",
    "        \"\"\"\n",
    "        if not self.solutions:\n",
    "            print(\"No solutions to analyze.\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Create a list of dictionaries to build the DataFrame.\n",
    "        df_data = []\n",
    "        for i, sol in enumerate(self.solutions):\n",
    "            row = {'Solution': i + 1}\n",
    "            \n",
    "            # Add variable and multiplier values.\n",
    "            for var in self.variables:\n",
    "                row[str(var)] = sol.get(str(var), np.nan)\n",
    "            \n",
    "            for mult in self.multipliers:\n",
    "                row[str(mult)] = sol.get(str(mult), np.nan)\n",
    "            \n",
    "            # Add objective value and constraint violations.\n",
    "            row['Objective_Value'] = sol.get('objective_value', np.nan)\n",
    "            \n",
    "            for j, const_val in enumerate(sol.get('constraint_values', [])):\n",
    "                row[f'Constraint_{j+1}_Violation'] = abs(const_val)\n",
    "            \n",
    "            df_data.append(row)\n",
    "        \n",
    "        df = pd.DataFrame(df_data)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"SOLUTION ANALYSIS\")\n",
    "            print(\"=\"*60)\n",
    "            print(df.round(6))\n",
    "            \n",
    "            # Print key summary statistics.\n",
    "            print(\"\\nSummary Statistics:\")\n",
    "            print(f\"Number of solutions: {len(self.solutions)}\")\n",
    "            if len(self.solutions) > 0:\n",
    "                obj_values = [sol['objective_value'] for sol in self.solutions]\n",
    "                best_val = min(obj_values) if self.problem_type == 'minimize' else max(obj_values)\n",
    "                worst_val = max(obj_values) if self.problem_type == 'minimize' else min(obj_values)\n",
    "                print(f\"Best objective value: {best_val:.6f}\")\n",
    "                print(f\"Worst objective value: {worst_val:.6f}\")\n",
    "                print(f\"Mean objective value: {np.mean(obj_values):.6f}\")\n",
    "                print(f\"Std objective value: {np.std(obj_values):.6f}\")\n",
    "    \n",
    "        return df\n",
    "    \n",
    "    def export_results(self, filename: Optional[str] = None) -> None:\n",
    "        \"\"\"\n",
    "        Exports the optimization results to a JSON file.\n",
    "        \n",
    "        The JSON format is easy to read and parse, making it a convenient way to\n",
    "        save the complete state of the solved problem, including the problem\n",
    "        definition and all found solutions.\n",
    "        \n",
    "        Args:\n",
    "            filename: The name of the file to save to. If None, a default\n",
    "                      filename is generated with a timestamp.\n",
    "        \"\"\"\n",
    "        if not filename:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"lagrange_results_{timestamp}.json\"\n",
    "        \n",
    "        # Structure the data to be exported.\n",
    "        export_data = {\n",
    "            'problem': {\n",
    "                'type': self.problem_type,\n",
    "                'variables': [str(var) for var in self.variables],\n",
    "                'objective': str(self.objective),\n",
    "                'constraints': [str(const) for const in self.constraints],\n",
    "                'lagrangian': str(self.lagrangian)\n",
    "            },\n",
    "            'solutions': self.solutions,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'num_solutions': len(self.solutions)\n",
    "        }\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(export_data, f, indent=2, default=str)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\\nResults exported to {filename}\")\n",
    "    \n",
    "    def solve_complete(self, \n",
    "                       objective: Union[str, sp.Expr],\n",
    "                       constraints: Union[List[str], List[sp.Expr]], \n",
    "                       variables: Union[List[str], List[sp.Symbol]],\n",
    "                       problem_type: str = 'minimize',\n",
    "                       try_symbolic: bool = True,\n",
    "                       try_numerical: bool = True,\n",
    "                       visualize: bool = True,\n",
    "                       export: bool = False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Runs the complete optimization pipeline from start to finish.\n",
    "        \n",
    "        This is the main public method that orchestrates all the steps:\n",
    "        - Setting up the problem.\n",
    "        - Attempting a symbolic solution.\n",
    "        - Falling back to a numerical solution if symbolic fails or is not requested.\n",
    "        - Verifying the solutions against the KKT conditions.\n",
    "        - Creating visualizations (for 2D problems).\n",
    "        - Analyzing and reporting the results in a DataFrame.\n",
    "        - Optionally exporting the results to a file.\n",
    "        \n",
    "        Args:\n",
    "            objective: The objective function.\n",
    "            constraints: The list of constraint equations.\n",
    "            variables: The list of variables.\n",
    "            problem_type: 'minimize' or 'maximize'.\n",
    "            try_symbolic: Whether to attempt symbolic solution first.\n",
    "            try_numerical: Whether to attempt numerical solution.\n",
    "            visualize: Whether to generate plots (for 2D problems).\n",
    "            export: Whether to export results to a JSON file.\n",
    "            \n",
    "        Returns:\n",
    "            A pandas DataFrame with the detailed solution analysis.\n",
    "        \"\"\"\n",
    "        # Setup problem, clearing any previous solutions.\n",
    "        self.setup_problem(objective, constraints, variables, problem_type)\n",
    "        self.solutions = []\n",
    "        \n",
    "        # Attempt symbolic solution.\n",
    "        if try_symbolic:\n",
    "            symbolic_solutions = self.solve_symbolic()\n",
    "            if not symbolic_solutions and self.verbose:\n",
    "                print(\"Symbolic solution unsuccessful, proceeding with numerical methods...\")\n",
    "        \n",
    "        # Attempt numerical solution.\n",
    "        if try_numerical:\n",
    "            self.solve_numerical()\n",
    "        \n",
    "        # Verify and analyze all found solutions.\n",
    "        self.verify_solutions()\n",
    "        \n",
    "        # Visualize if conditions are met.\n",
    "        if visualize and len(self.variables) == 2 and self.solutions:\n",
    "            self.visualize_2d()\n",
    "        \n",
    "        # Analyze and return the results.\n",
    "        df = self.analyze_solutions()\n",
    "        \n",
    "        # Export if requested.\n",
    "        if export:\n",
    "            self.export_results()\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# INTERACTIVE MODE\n",
    "# ==============================================================================\n",
    "# This function provides a command-line interface for the solver, allowing users\n",
    "# to easily test pre-defined examples or input their own problems.\n",
    "\n",
    "def interactive_solver():\n",
    "    \"\"\"Interactive command-line interface for the optimizer.\"\"\"\n",
    "    print(\"🎯 Advanced Lagrange Multiplier Solver\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    optimizer = AdvancedLagrangeOptimizer(verbose=True)\n",
    "    \n",
    "    # Predefined examples for quick demonstration.\n",
    "    examples = {\n",
    "        '1': {\n",
    "            'name': 'Basic: Minimize x² + y²',\n",
    "            'objective': 'x**2 + y**2',\n",
    "            'constraints': ['x + y - 1'],\n",
    "            'variables': ['x', 'y'],\n",
    "            'type': 'minimize'\n",
    "        },\n",
    "        '2': {\n",
    "            'name': 'Economics: Utility Maximization',\n",
    "            'objective': 'x*y',\n",
    "            'constraints': ['2*x + 3*y - 12'],\n",
    "            'variables': ['x', 'y'],\n",
    "            'type': 'maximize'\n",
    "        },\n",
    "        '3': {\n",
    "            'name': 'Geometry: Distance to Curve',\n",
    "            'objective': '(x-1)**2 + (y-2)**2',\n",
    "            'constraints': ['x**2 + y**2 - 1'],\n",
    "            'variables': ['x', 'y'],\n",
    "            'type': 'minimize'\n",
    "        },\n",
    "        '4': {\n",
    "            'name': 'Physics: Constrained Motion',\n",
    "            'objective': '0.5*x**2 + 2*y**2',\n",
    "            'constraints': ['x**2 + y**2 - 4'],\n",
    "            'variables': ['x', 'y'],\n",
    "            'type': 'minimize'\n",
    "        },\n",
    "        '5': {\n",
    "            'name': '3D: Minimize x² + y² + z²',\n",
    "            'objective': 'x**2 + y**2 + z**2',\n",
    "            'constraints': ['x + y + z - 1', 'x**2 + y**2 - 1'],\n",
    "            'variables': ['x', 'y', 'z'],\n",
    "            'type': 'minimize'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\nOptions:\")\n",
    "        print(\"📚 Examples:\")\n",
    "        for key, example in examples.items():\n",
    "            print(f\"  {key}. {example['name']}\")\n",
    "        print(\"  6. Custom problem\")\n",
    "        print(\"  7. Exit\")\n",
    "        \n",
    "        choice = input(\"\\nSelect option (1-7): \").strip()\n",
    "        \n",
    "        if choice == '7':\n",
    "            break\n",
    "        elif choice in examples:\n",
    "            example = examples[choice]\n",
    "            print(f\"\\nLoaded: {example['name']}\")\n",
    "            \n",
    "            df = optimizer.solve_complete(\n",
    "                objective=example['objective'],\n",
    "                constraints=example['constraints'],\n",
    "                variables=example['variables'],\n",
    "                problem_type=example['type'],\n",
    "                visualize=True,\n",
    "                export=False\n",
    "            )\n",
    "            \n",
    "        elif choice == '6':\n",
    "            print(\"\\n🔧 Custom Problem Setup:\")\n",
    "            \n",
    "            # Prompt user for problem details.\n",
    "            prob_type = input(\"Problem type (minimize/maximize) [minimize]: \").strip().lower()\n",
    "            if prob_type not in ['minimize', 'maximize']:\n",
    "                prob_type = 'minimize'\n",
    "            \n",
    "            vars_input = input(\"Variables (space-separated, e.g., 'x y z'): \").strip()\n",
    "            variables = vars_input.split()\n",
    "            \n",
    "            if not variables:\n",
    "                print(\"❌ No variables provided!\")\n",
    "                continue\n",
    "            \n",
    "            objective = input(f\"Objective function f({','.join(variables)}): \").strip()\n",
    "            if not objective:\n",
    "                print(\"❌ No objective function provided!\")\n",
    "                continue\n",
    "            \n",
    "            print(\"Enter constraints (one per line, empty line to finish):\")\n",
    "            constraints = []\n",
    "            while True:\n",
    "                constraint = input(\"  Constraint (=0): \").strip()\n",
    "                if not constraint:\n",
    "                    break\n",
    "                constraints.append(constraint)\n",
    "            \n",
    "            if not constraints:\n",
    "                print(\"❌ No constraints provided!\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Solve the custom problem.\n",
    "                df = optimizer.solve_complete(\n",
    "                    objective=objective,\n",
    "                    constraints=constraints,\n",
    "                    variables=variables,\n",
    "                    problem_type=prob_type,\n",
    "                    visualize=True,\n",
    "                    export=True\n",
    "                )\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error solving problem: {e}\")\n",
    "        \n",
    "        else:\n",
    "            print(\"❌ Invalid choice!\")\n",
    "        \n",
    "        input(\"\\nPress Enter to continue...\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "# This block demonstrates the solver's capabilities with various examples,\n",
    "# performance benchmarks, and additional utility functions.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: Basic constrained optimization.\n",
    "    # This example minimizes the distance from the origin (x²+y²) subject to a\n",
    "    # linear constraint (a line). The solution is the point on the line closest to the origin.\n",
    "    print(\"Example 1: Basic Constrained Optimization\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    optimizer = AdvancedLagrangeOptimizer()\n",
    "    df = optimizer.solve_complete(\n",
    "        objective=\"x**2 + y**2\",\n",
    "        constraints=[\"x + y - 1\"],\n",
    "        variables=[\"x\", \"y\"],\n",
    "        problem_type=\"minimize\",\n",
    "        visualize=True,\n",
    "        export=False\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Example 2: Economics - Utility Maximization\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Example 2: Utility maximization.\n",
    "    # A classic economics problem: maximize a utility function (x*y) subject to a\n",
    "    # budget constraint (a line). The solution represents the optimal consumption\n",
    "    # bundle given the prices and income.\n",
    "    optimizer2 = AdvancedLagrangeOptimizer()\n",
    "    df2 = optimizer2.solve_complete(\n",
    "        objective=\"x*y\",\n",
    "        constraints=[\"2*x + 3*y - 12\"],\n",
    "        variables=[\"x\", \"y\"],\n",
    "        problem_type=\"maximize\",\n",
    "        visualize=True,\n",
    "        export=False\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Example 3: Multi-constraint 3D Problem\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Example 3: Multiple constraints in 3D.\n",
    "    # This problem finds the point closest to the origin (x²+y²+z²) that lies on\n",
    "    # the intersection of a plane (x+y+z=1) and a cylinder (x²+y²=1).\n",
    "    optimizer3 = AdvancedLagrangeOptimizer()\n",
    "    df3 = optimizer3.solve_complete(\n",
    "        objective=\"x**2 + y**2 + z**2\",\n",
    "        constraints=[\"x + y + z - 1\", \"x**2 + y**2 - 1\"],\n",
    "        variables=[\"x\", \"y\", \"z\"],\n",
    "        problem_type=\"minimize\",\n",
    "        visualize=False,  # 2D visualization is not applicable here.\n",
    "        export=False\n",
    "    )\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # ADVANCED ANALYSIS AND BENCHMARKING\n",
    "    # ==============================================================================\n",
    "    # This section demonstrates more advanced use cases of the optimizer class,\n",
    "    # including comparing symbolic vs. numerical methods, performing sensitivity\n",
    "    # analysis, and benchmarking performance.\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ADVANCED ANALYSIS AND COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    def compare_methods(objective, constraints, variables, problem_type=\"minimize\"):\n",
    "        \"\"\"Compares the results and performance of symbolic vs numerical methods.\"\"\"\n",
    "        print(f\"\\nComparing methods for: {problem_type} {objective}\")\n",
    "        print(f\"Subject to: {constraints}\")\n",
    "        \n",
    "        optimizer_sym = AdvancedLagrangeOptimizer(verbose=False)\n",
    "        optimizer_num = AdvancedLagrangeOptimizer(verbose=False)\n",
    "        \n",
    "        optimizer_sym.setup_problem(objective, constraints, variables, problem_type)\n",
    "        optimizer_num.setup_problem(objective, constraints, variables, problem_type)\n",
    "        \n",
    "        sym_solutions = optimizer_sym.solve_symbolic()\n",
    "        num_solutions = optimizer_num.solve_numerical(num_random_starts=100)\n",
    "        \n",
    "        print(f\"Symbolic solutions: {len(sym_solutions)}\")\n",
    "        print(f\"Numerical solutions: {len(num_solutions)}\")\n",
    "        \n",
    "        if sym_solutions and num_solutions:\n",
    "            sym_obj = sym_solutions[0]['objective_value']\n",
    "            num_obj = num_solutions[0]['objective_value']\n",
    "            print(f\"Best symbolic objective: {sym_obj:.8f}\")\n",
    "            print(f\"Best numerical objective: {num_obj:.8f}\")\n",
    "            print(f\"Difference: {abs(sym_obj - num_obj):.2e}\")\n",
    "        \n",
    "        return sym_solutions, num_solutions\n",
    "    \n",
    "    # Test a set of problems to see how the methods compare.\n",
    "    test_problems = [\n",
    "        (\"x**2 + y**2\", [\"x + y - 1\"], [\"x\", \"y\"], \"minimize\"),\n",
    "        (\"x*y\", [\"2*x + 3*y - 12\"], [\"x\", \"y\"], \"maximize\"),\n",
    "        (\"(x-1)**2 + (y-2)**2\", [\"x**2 + y**2 - 1\"], [\"x\", \"y\"], \"minimize\"),\n",
    "        (\"x**2 + 2*y**2\", [\"x**2 + y**2 - 4\"], [\"x\", \"y\"], \"minimize\")\n",
    "    ]\n",
    "    \n",
    "    for obj, const, vars, prob_type in test_problems:\n",
    "        compare_methods(obj, const, vars, prob_type)\n",
    "    \n",
    "    # Sensitivity analysis.\n",
    "    # The Lagrange multiplier, λ, has a powerful economic and physical interpretation:\n",
    "    # it represents the \"shadow price\" of the constraint. It tells us how much the\n",
    "    # optimal objective value changes for a small change in the constraint.\n",
    "    # Specifically, ∂f*/∂c = λ, where f* is the optimal value and c is a\n",
    "    # parameter in the constraint (g(x)=c).\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SENSITIVITY ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    def sensitivity_analysis():\n",
    "        \"\"\"Analyzes how solutions change with constraint parameters.\"\"\"\n",
    "        print(\"Analyzing sensitivity to constraint parameter changes...\")\n",
    "        \n",
    "        # We'll analyze the problem: minimize x² + y² subject to x + y = c.\n",
    "        results = []\n",
    "        c_values = np.linspace(0.5, 2.0, 11)\n",
    "        \n",
    "        for c in c_values:\n",
    "            optimizer = AdvancedLagrangeOptimizer(verbose=False)\n",
    "            constraint = f\"x + y - {c}\"\n",
    "            \n",
    "            try:\n",
    "                optimizer.solve_complete(\n",
    "                    objective=\"x**2 + y**2\",\n",
    "                    constraints=[constraint],\n",
    "                    variables=[\"x\", \"y\"],\n",
    "                    problem_type=\"minimize\",\n",
    "                    visualize=False,\n",
    "                    export=False\n",
    "                )\n",
    "                \n",
    "                if optimizer.solutions:\n",
    "                    sol = optimizer.solutions[0]\n",
    "                    results.append({\n",
    "                        'c': c,\n",
    "                        'x': sol['x'],\n",
    "                        'y': sol['y'],\n",
    "                        'objective': sol['objective_value'],\n",
    "                        'lambda': sol.get('λ1', 0)\n",
    "                    })\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if results:\n",
    "            df_sensitivity = pd.DataFrame(results)\n",
    "            print(\"\\nSensitivity Analysis Results:\")\n",
    "            print(df_sensitivity.round(6))\n",
    "            \n",
    "            # Plot the results to visualize the relationships.\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "            \n",
    "            # Plotting optimal variable values vs. c.\n",
    "            axes[0, 0].plot(df_sensitivity['c'], df_sensitivity['x'], 'bo-', label='x*')\n",
    "            axes[0, 0].plot(df_sensitivity['c'], df_sensitivity['y'], 'ro-', label='y*')\n",
    "            axes[0, 0].set_xlabel('Constraint parameter c')\n",
    "            axes[0, 0].set_ylabel('Optimal values')\n",
    "            axes[0, 0].set_title('Optimal Variables vs Constraint Parameter')\n",
    "            axes[0, 0].legend()\n",
    "            axes[0, 0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Plotting optimal objective value vs. c.\n",
    "            axes[0, 1].plot(df_sensitivity['c'], df_sensitivity['objective'], 'go-')\n",
    "            axes[0, 1].set_xlabel('Constraint parameter c')\n",
    "            axes[0, 1].set_ylabel('Optimal objective value')\n",
    "            axes[0, 1].set_title('Optimal Objective vs Constraint Parameter')\n",
    "            axes[0, 1].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Plotting the Lagrange multiplier λ vs. c.\n",
    "            axes[1, 0].plot(df_sensitivity['c'], df_sensitivity['lambda'], 'mo-')\n",
    "            axes[1, 0].set_xlabel('Constraint parameter c')\n",
    "            axes[1, 0].set_ylabel('Lagrange multiplier λ')\n",
    "            axes[1, 0].set_title('Lagrange Multiplier vs Constraint Parameter')\n",
    "            axes[1, 0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Demonstrating the \"shadow price\" interpretation: λ ≈ ∂f*/∂c.\n",
    "            # The slope of the objective vs. c curve should be approximately equal to λ.\n",
    "            axes[1, 1].plot(df_sensitivity['c'][:-1], \n",
    "                             np.diff(df_sensitivity['objective']) / np.diff(df_sensitivity['c']), \n",
    "                             'co-', label='Numerical derivative')\n",
    "            axes[1, 1].plot(df_sensitivity['c'], df_sensitivity['lambda'], 'mo--', \n",
    "                             label='Lagrange multiplier', alpha=0.7)\n",
    "            axes[1, 1].set_xlabel('Constraint parameter c')\n",
    "            axes[1, 1].set_ylabel('Shadow price (∂f*/∂c)')\n",
    "            axes[1, 1].set_title('Shadow Price Analysis')\n",
    "            axes[1, 1].legend()\n",
    "            axes[1, 1].grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    sensitivity_analysis()\n",
    "    \n",
    "    # Performance benchmark.\n",
    "    # This section compares the execution time and success rate of the symbolic\n",
    "    # and numerical methods on different types of problems.\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PERFORMANCE BENCHMARK\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    def benchmark_methods():\n",
    "        \"\"\"Benchmarks the performance of symbolic vs. numerical solution methods.\"\"\"\n",
    "        import time\n",
    "        \n",
    "        problems = [\n",
    "            (\"Simple\", \"x**2 + y**2\", [\"x + y - 1\"], [\"x\", \"y\"]),\n",
    "            (\"Nonlinear\", \"x**2 + y**4\", [\"x**2 + y**2 - 1\"], [\"x\", \"y\"]),\n",
    "            (\"Multi-constraint\", \"x**2 + y**2 + z**2\", \n",
    "             [\"x + y + z - 1\", \"x**2 + y**2 - 1\"], [\"x\", \"y\", \"z\"]),\n",
    "        ]\n",
    "        \n",
    "        benchmark_results = []\n",
    "        \n",
    "        for name, obj, const, vars in problems:\n",
    "            print(f\"\\nBenchmarking: {name}\")\n",
    "            \n",
    "            # Benchmark symbolic method.\n",
    "            optimizer_sym = AdvancedLagrangeOptimizer(verbose=False)\n",
    "            optimizer_sym.setup_problem(obj, const, vars)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            sym_solutions = optimizer_sym.solve_symbolic()\n",
    "            sym_time = time.time() - start_time\n",
    "            \n",
    "            # Benchmark numerical method.\n",
    "            optimizer_num = AdvancedLagrangeOptimizer(verbose=False)\n",
    "            optimizer_num.setup_problem(obj, const, vars)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            num_solutions = optimizer_num.solve_numerical(num_random_starts=50)\n",
    "            num_time = time.time() - start_time\n",
    "            \n",
    "            benchmark_results.append({\n",
    "                'Problem': name,\n",
    "                'Symbolic_Time': sym_time,\n",
    "                'Symbolic_Solutions': len(sym_solutions),\n",
    "                'Numerical_Time': num_time,\n",
    "                'Numerical_Solutions': len(num_solutions),\n",
    "                'Speedup': num_time / sym_time if sym_time > 0 else np.inf\n",
    "            })\n",
    "            \n",
    "            print(f\"  Symbolic: {len(sym_solutions)} solutions in {sym_time:.4f}s\")\n",
    "            print(f\"  Numerical: {len(num_solutions)} solutions in {num_time:.4f}s\")\n",
    "        \n",
    "        df_benchmark = pd.DataFrame(benchmark_results)\n",
    "        print(\"\\nBenchmark Summary:\")\n",
    "        print(df_benchmark)\n",
    "    \n",
    "    benchmark_methods()\n",
    "    \n",
    "    # Start the interactive command-line interface.\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"INTERACTIVE MODE\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"Starting interactive solver...\")\n",
    "    \n",
    "    try:\n",
    "        interactive_solver()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nExiting interactive solver. Thank you!\")\n",
    "    \n",
    "    print(\"\\n🎯 Advanced Lagrange Multiplier Solver - Session Complete!\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # ADDITIONAL UTILITY FUNCTIONS\n",
    "    # ==============================================================================\n",
    "    # These functions demonstrate how the `AdvancedLagrangeOptimizer` can be used\n",
    "    # as a component in a larger scientific computing workflow.\n",
    "    \n",
    "    def create_optimization_report(optimizer, filename=None):\n",
    "        \"\"\"Creates a comprehensive HTML report of the optimization results.\"\"\"\n",
    "        if not filename:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"optimization_report_{timestamp}.html\"\n",
    "        \n",
    "        # The HTML content is built as a multi-line string.\n",
    "        html_content = f\"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html>\n",
    "        <head>\n",
    "            <title>Optimization Report</title>\n",
    "            <style>\n",
    "                body {{ font-family: Arial, sans-serif; margin: 40px; }}\n",
    "                .header {{ background-color: #f0f0f0; padding: 20px; border-radius: 5px; }}\n",
    "                .solution {{ background-color: #e8f4fd; padding: 15px; margin: 10px 0; border-radius: 5px; }}\n",
    "                table {{ border-collapse: collapse; width: 100%; }}\n",
    "                th, td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}\n",
    "                th {{ background-color: #f2f2f2; }}\n",
    "                .success {{ color: green; }}\n",
    "                .warning {{ color: orange; }}\n",
    "                .error {{ color: red; }}\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <div class=\"header\">\n",
    "                <h1>🎯 Lagrange Multiplier Optimization Report</h1>\n",
    "                <p><strong>Generated:</strong> {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}</p>\n",
    "                <p><strong>Problem Type:</strong> {optimizer.problem_type.capitalize()}</p>\n",
    "                <p><strong>Objective:</strong> {optimizer.objective}</p>\n",
    "                <p><strong>Constraints:</strong> {[str(c) for c in optimizer.constraints]}</p>\n",
    "                <p><strong>Variables:</strong> {[str(v) for v in optimizer.variables]}</p>\n",
    "            </div>\n",
    "            \n",
    "            <h2>📊 Solutions Found: {len(optimizer.solutions)}</h2>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Loop through each solution to add it to the report.\n",
    "        for i, sol in enumerate(optimizer.solutions):\n",
    "            html_content += f\"\"\"\n",
    "            <div class=\"solution\">\n",
    "                <h3>Solution {i+1}</h3>\n",
    "                <table>\n",
    "                    <tr><th>Variable/Parameter</th><th>Value</th></tr>\n",
    "            \"\"\"\n",
    "            \n",
    "            for var in optimizer.variables:\n",
    "                html_content += f\"<tr><td>{var}</td><td>{sol.get(str(var), 'N/A'):.6f}</td></tr>\"\n",
    "            \n",
    "            for mult in optimizer.multipliers:\n",
    "                html_content += f\"<tr><td>{mult}</td><td>{sol.get(str(mult), 'N/A'):.6f}</td></tr>\"\n",
    "            \n",
    "            html_content += f\"<tr><td><strong>Objective Value</strong></td><td><strong>{sol['objective_value']:.6f}</strong></td></tr>\"\n",
    "            html_content += \"</table>\"\n",
    "            \n",
    "            # Add a verification section for constraints.\n",
    "            html_content += \"<h4>Constraint Verification:</h4><ul>\"\n",
    "            for j, const_val in enumerate(sol.get('constraint_values', [])):\n",
    "                status = \"✓ Satisfied\" if abs(const_val) < 1e-6 else \"✗ Violated\"\n",
    "                color = \"success\" if abs(const_val) < 1e-6 else \"error\"\n",
    "                html_content += f'<li class=\"{color}\">Constraint {j+1}: {const_val:.2e} {status}</li>'\n",
    "            html_content += \"</ul></div>\"\n",
    "        \n",
    "        html_content += \"\"\"\n",
    "            </body>\n",
    "            </html>\n",
    "        \"\"\"\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(html_content)\n",
    "        \n",
    "        print(f\"📄 Comprehensive report saved to {filename}\")\n",
    "    \n",
    "    def batch_solve(problem_list, output_dir=\"lagrange_results\"):\n",
    "        \"\"\"Solves multiple optimization problems in a batch and saves results.\"\"\"\n",
    "        import os\n",
    "        \n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for i, problem in enumerate(problem_list):\n",
    "            print(f\"\\nSolving problem {i+1}/{len(problem_list)}: {problem.get('name', 'Unnamed')}\")\n",
    "            \n",
    "            try:\n",
    "                optimizer = AdvancedLagrangeOptimizer(verbose=False)\n",
    "                df = optimizer.solve_complete(\n",
    "                    objective=problem['objective'],\n",
    "                    constraints=problem['constraints'],\n",
    "                    variables=problem['variables'],\n",
    "                    problem_type=problem.get('type', 'minimize'),\n",
    "                    visualize=False,\n",
    "                    export=False\n",
    "                )\n",
    "                \n",
    "                # Save individual results for each problem.\n",
    "                problem_name = problem.get('name', f'problem_{i+1}').replace(' ', '_')\n",
    "                optimizer.export_results(f\"{output_dir}/{problem_name}_results.json\")\n",
    "                create_optimization_report(optimizer, f\"{output_dir}/{problem_name}_report.html\")\n",
    "                \n",
    "                # Append a summary of the result.\n",
    "                results.append({\n",
    "                    'name': problem.get('name', f'Problem {i+1}'),\n",
    "                    'status': 'Success',\n",
    "                    'num_solutions': len(optimizer.solutions),\n",
    "                    'best_objective': min(s['objective_value'] for s in optimizer.solutions) if optimizer.solutions else None\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                # Handle cases where a problem fails to solve.\n",
    "                results.append({\n",
    "                    'name': problem.get('name', f'Problem {i+1}'),\n",
    "                    'status': f'Failed: {str(e)}',\n",
    "                    'num_solutions': 0,\n",
    "                    'best_objective': None\n",
    "                })\n",
    "        \n",
    "        # Save a final summary of the entire batch.\n",
    "        batch_df = pd.DataFrame(results)\n",
    "        batch_df.to_csv(f\"{output_dir}/batch_summary.csv\", index=False)\n",
    "        print(f\"\\n📊 Batch processing complete! Results saved to {output_dir}/\")\n",
    "        print(batch_df)\n",
    "        \n",
    "        return batch_df\n",
    "\n",
    "# Example batch processing:\n",
    "# This section demonstrates how to solve a list of problems automatically.\n",
    "if __name__ == \"__main__\":\n",
    "    # Define a list of optimization problems to solve.\n",
    "    batch_problems = [\n",
    "        {\n",
    "            'name': 'Basic Quadratic',\n",
    "            'objective': 'x**2 + y**2',\n",
    "            'constraints': ['x + y - 1'],\n",
    "            'variables': ['x', 'y'],\n",
    "            'type': 'minimize'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Utility Maximization',\n",
    "            'objective': 'x*y',\n",
    "            'constraints': ['2*x + 3*y - 12'],\n",
    "            'variables': ['x', 'y'],\n",
    "            'type': 'maximize'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Geometric Distance',\n",
    "            'objective': '(x-2)**2 + (y-3)**2',\n",
    "            'constraints': ['x**2 + y**2 - 1'],\n",
    "            'variables': ['x', 'y'],\n",
    "            'type': 'minimize'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Uncomment the line below to run the batch processing.\n",
    "    # batch_results = batch_solve(batch_problems)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
